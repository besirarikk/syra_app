/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * CHAT ORCHESTRATOR - FIXED VERSION
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Orchestrates all chat logic with improved error handling
 */

import { openai } from "../config/openaiClient.js";
import { detectIntentType, getChatConfig } from "../domain/intentEngine.js";
import { buildUltimatePersona, normalizeTone } from "../domain/personaEngine.js";
import { extractDeepTraits } from "../domain/traitEngine.js";
import { predictOutcome } from "../domain/outcomePredictionEngine.js";
import { detectUserPatterns } from "../domain/patternEngine.js";
import { detectGenderSmart } from "../domain/genderEngine.js";
import {
  getUserProfile,
  updateUserProfile,
  incrementGenderAttempts,
  updateUserGender,
} from "../firestore/userProfileRepository.js";
import {
  getConversationHistory,
  saveConversationHistory,
} from "../firestore/conversationRepository.js";

/**
 * Process chat request and generate AI response
 * 
 * @param {string} uid - User ID
 * @param {string} message - User message
 * @param {string} replyTo - Message being replied to (optional)
 * @param {boolean} isPremium - Premium status
 */
export async function processChat(uid, message, replyTo, isPremium) {
  const startTime = Date.now();

  // CRITICAL: Check OpenAI availability first
  if (!openai) {
    console.error(`[${uid}] ğŸ”¥ CRITICAL: OpenAI client is null - API key missing!`);
    throw new Error("OpenAI not configured - API key missing");
  }

  const safeMessage = String(message).slice(0, 5000);

  const [userProfile, historyData] = await Promise.all([
    getUserProfile(uid),
    getConversationHistory(uid),
  ]);

  const history = historyData.messages || [];
  const conversationSummary = historyData.summary;

  console.log(
    `[${uid}] Processing - Premium: ${isPremium}, History: ${history.length}, Summary: ${!!conversationSummary}`
  );

  const intent = detectIntentType(safeMessage, history);
  const { model, temperature, maxTokens } = getChatConfig(
    intent,
    isPremium,
    userProfile
  );

  console.log(
    `[${uid}] Intent: ${intent}, Model: ${model}, Temp: ${temperature}, MaxTokens: ${maxTokens}`
  );

  let detectedGender = await detectGenderSmart(safeMessage, userProfile);

  if (detectedGender !== userProfile.gender && detectedGender !== "belirsiz") {
    await updateUserGender(uid, detectedGender);
    userProfile.gender = detectedGender;
    console.log(`[${uid}] Gender detected: ${detectedGender}`);
  } else if (detectedGender === "belirsiz" && userProfile.genderAttempts < 3) {
    await incrementGenderAttempts(uid);
  }

  const extractedTraits = await extractDeepTraits(safeMessage, replyTo, history);

  console.log(
    `[${uid}] Traits - Tone: ${extractedTraits.tone}, Urgency: ${extractedTraits.urgency}, Flags: R${extractedTraits.flags.red.length}/G${extractedTraits.flags.green.length}`
  );

  const patterns = await detectUserPatterns(history, userProfile, isPremium);

  if (patterns) {
    console.log(
      `[${uid}] Patterns detected - Mistakes: ${patterns.repeatingMistakes?.length || 0}, Type: ${patterns.relationshipType}`
    );
  }

  const outcomePrediction = await predictOutcome(safeMessage, history, isPremium);

  if (outcomePrediction) {
    console.log(
      `[${uid}] Outcome - Interest: ${outcomePrediction.interestLevel}%, Date: ${outcomePrediction.dateProbability}%`
    );
  }

  const newTone = normalizeTone(extractedTraits?.tone);
  userProfile.lastTone = newTone;

  if (
    extractedTraits.relationshipStage &&
    extractedTraits.relationshipStage !== "none"
  ) {
    userProfile.relationshipStage = extractedTraits.relationshipStage;
  }

  if (
    extractedTraits.attachmentStyle &&
    extractedTraits.attachmentStyle !== "unknown"
  ) {
    userProfile.attachmentStyle = extractedTraits.attachmentStyle;
  }

  userProfile.totalAdviceGiven = (userProfile.totalAdviceGiven || 0) + 1;

  updateUserProfile(uid, userProfile).catch((e) => {
    console.error(`[${uid}] User profile save error:`, e);
  });

  const persona = buildUltimatePersona(
    isPremium,
    userProfile,
    extractedTraits,
    patterns,
    conversationSummary
  );

  const replyContext = replyTo
    ? `
ğŸ¯ Ã–ZEL YANIT MODU:
KullanÄ±cÄ± ÅŸu mesaja yanÄ±t veriyor: "${String(replyTo).slice(0, 400)}"

â€¢ CevabÄ±nÄ± Ã¶zellikle bu mesaja gÃ¶re kurgula.
â€¢ KullanÄ±cÄ±nÄ±n yanÄ±tladÄ±ÄŸÄ± mesaj ana odak olsun.
`
    : "KullanÄ±cÄ± Ã¶zel bir mesaja yanÄ±t vermiyor. Normal sohbet.";

  const enrichedContext =
    isPremium && (history.length > 5 || conversationSummary)
      ? `
ğŸ“Š KAPSAMLI CONTEXT:

${
  conversationSummary
    ? `UZUN VADELÄ° Ã–ZET:
${conversationSummary}`
    : ""
}

Ä°STATÄ°STÄ°K:
â€¢ Toplam mesaj: ${userProfile.messageCount}
â€¢ Aktif history: ${history.length}
â€¢ Ä°liÅŸki aÅŸamasÄ±: ${userProfile.relationshipStage}
â€¢ Attachment: ${userProfile.attachmentStyle}
â€¢ Son ton: ${userProfile.lastTone}

${
  outcomePrediction
    ? `
OUTCOME (iÃ§sel â€“ direkt sÃ¶yleme, ima et):
â€¢ Ä°lgi: %${outcomePrediction.interestLevel}
â€¢ BuluÅŸma: %${outcomePrediction.dateProbability}
â€¢ Prospect: ${outcomePrediction.relationshipProspect}
â€¢ Riskler: ${outcomePrediction.risks?.join(", ") || "yok"}
â€¢ FÄ±rsatlar: ${outcomePrediction.opportunities?.join(", ") || "var"}
`
    : ""
}

${
  patterns
    ? `
PATTERN:
â€¢ Tekrarlayan hata sayÄ±sÄ±: ${patterns.repeatingMistakes?.length || 0}
â€¢ Ä°liÅŸki tipi: ${patterns.relationshipType}
â€¢ Attachment: ${patterns.attachmentIndicators}
`
    : ""
}
`
      : "";

  const systemMessages = [
    { role: "system", content: persona },
    { role: "system", content: replyContext },
  ];

  if (enrichedContext) {
    systemMessages.push({
      role: "system",
      content: enrichedContext,
    });
  }

  if (
    extractedTraits.urgency === "high" ||
    extractedTraits.urgency === "critical"
  ) {
    systemMessages.push({
      role: "system",
      content:
        "âš ï¸ ACÄ°L DURUM: Daha empatik, daha net ve hÄ±zlÄ± Ã§Ã¶zÃ¼m odaklÄ± yanÄ±t ver.",
    });
  }

  if (extractedTraits.needsSupport) {
    systemMessages.push({
      role: "system",
      content:
        "ğŸ’™ KullanÄ±cÄ± duygusal destek istiyor. Destekleyici, yargÄ±lamayan ve sakin bir tonda ol.",
    });
  }

  const recentHistory = history.slice(-10);

  const contextMessages = [
    ...systemMessages,
    ...recentHistory,
    { role: "user", content: safeMessage },
  ];

  let replyText = null;
  let openaiError = null;

  try {
    console.log(`[${uid}] Calling OpenAI API with model: ${model}`);
    
    const completion = await openai.chat.completions.create({
      model,
      messages: contextMessages,
      temperature,
      max_tokens: maxTokens,
      presence_penalty: 0.6,
      frequency_penalty: 0.3,
    });

    console.log(`[${uid}] OpenAI response received`);

    if (!completion) {
      console.error(`[${uid}] ğŸ”¥ OpenAI returned null completion`);
      openaiError = "NULL_COMPLETION";
    } else if (!completion.choices || completion.choices.length === 0) {
      console.error(`[${uid}] ğŸ”¥ OpenAI returned empty choices array`);
      openaiError = "EMPTY_CHOICES";
    } else if (!completion.choices[0].message) {
      console.error(`[${uid}] ğŸ”¥ OpenAI choice has no message`);
      openaiError = "NO_MESSAGE";
    } else if (!completion.choices[0].message.content) {
      console.error(`[${uid}] ğŸ”¥ OpenAI message has no content`);
      openaiError = "NO_CONTENT";
    } else {
      replyText = completion.choices[0].message.content.trim();
      
      if (!replyText || replyText.length === 0) {
        console.error(`[${uid}] ğŸ”¥ OpenAI returned empty content after trim`);
        openaiError = "EMPTY_CONTENT";
      } else {
        console.log(`[${uid}] âœ… OpenAI success - Reply length: ${replyText.length} chars`);
      }
    }

    if (
      replyText &&
      isPremium &&
      (intent === "deep" || intent === "deep_analysis") &&
      replyText.length < 150
    ) {
      console.warn(
        `[${uid}] âš ï¸ Premium deep response unusually short: ${replyText.length} chars`
      );
    }

  } catch (e) {
    console.error(`[${uid}] ğŸ”¥ OpenAI API Error:`, e);
    console.error(`[${uid}] Error type: ${e.constructor.name}`);
    console.error(`[${uid}] Error message: ${e.message}`);
    
    if (e.code) {
      console.error(`[${uid}] Error code: ${e.code}`);
    }
    
    if (e.response) {
      console.error(`[${uid}] Error response status: ${e.response.status}`);
      console.error(`[${uid}] Error response data:`, JSON.stringify(e.response.data).slice(0, 500));
    }

    openaiError = e.message || "UNKNOWN_ERROR";
  }

  if (!replyText) {
    console.error(`[${uid}] ğŸ”¥ No reply text - using fallback. Error: ${openaiError}`);
    
    if (openaiError && openaiError.includes("rate_limit")) {
      replyText = "Kanka ÅŸu an Ã§ok yoÄŸunuz, 30 saniye sonra tekrar dener misin?";
    } else if (openaiError && openaiError.includes("timeout")) {
      replyText = "BaÄŸlantÄ± zaman aÅŸÄ±mÄ±na uÄŸradÄ± kanka. Bir daha dene lÃ¼tfen.";
    } else if (intent === "emergency") {
      replyText = "Kanka ÅŸu an sistem yoÄŸun ama ben buradayÄ±m. Derin nefes al, biraz sonra tekrar dene.";
    } else {
      replyText = "Sistem ÅŸu an cevap Ã¼retemedi kanka. LÃ¼tfen tekrar dene, bu sefer olacak! ğŸ’ª";
    }
    
    console.error(`[${uid}] ğŸš¨ FALLBACK MESSAGE SENT: ${replyText}`);
  }

  saveConversationHistory(uid, safeMessage, replyText, historyData).catch(
    (e) => {
      console.error(`[${uid}] History save error:`, e);
    }
  );

  const processingTime = Date.now() - startTime;
  console.log(
    `[${uid}] âœ… Processing complete: ${processingTime}ms, Intent: ${intent}, Model: ${model}, Success: ${!openaiError}`
  );

  return {
    reply: replyText,
    extractedTraits,
    outcomePrediction: isPremium ? outcomePrediction : undefined,
    patterns: isPremium ? patterns : undefined,
    meta: {
      intent,
      model,
      premium: isPremium,
      messageCount: userProfile.messageCount,
      processingTime,
      hasLongTermMemory: !!conversationSummary,
      hasPatterns: !!patterns,
      hadError: !!openaiError,
      errorType: openaiError || null,
    },
  };
}
